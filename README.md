# ğŸ’» ë¬´ì„ ë„¤íŠ¸ì›Œí¬ í”„ë¡œì íŠ¸ Cë°˜ 1ì¡°


## ì¡°ì› : ê¹€ ì‚°(RealSan1), ê¹€ë¯¼ìˆ˜(NanHangBok), ì¡°ì˜ì² (yeoncheoljo), ì´ì„ í˜¸(SolarHO)

<hr>

# ğŸš€í”„ë¡œì íŠ¸ ì£¼ì œ
- OpenCVë¥¼ í†µí•œ ì–¼êµ´ ì¸ì‹ê³¼ AI ëª¨ë¸íŒë‹¨(ì„±ë³„, ì—°ë ¹, ì•…ì„¸ì„œë¦¬) ë§ì¶¤í˜• ì˜¥ì™¸ ê´‘ê³  ì‹œìŠ¤í…œ

# ğŸ“ƒêµ¬í˜„ ê³„íš
- ì¹´ë©”ë¼ ëª¨ë“ˆê³¼ ë¼ì¦ˆë² ë¦¬íŒŒì´ì˜ ì—°ë™
- í”¼ì‚¬ì²´ ì†ì„± êµ¬ë¶„ AIëª¨ë¸(ì„±ë³„, ì—°ë ¹, ì•…ì„¸ì„œë¦¬) êµ¬ì¶•
- í•„ìš” ê´‘ê³  ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ Googel Cloud Storage êµ¬ì¶• ë° ê´‘ê³  ë°ì´í„° ì €ì¥
- íŒë‹¨ ë°ì´í„°ë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ ê´‘ê³  ì›¹ í˜ì´ì§€ êµ¬ì„±(Django í™œìš©)

# ğŸ› ï¸ì£¼ìš” ê¸°ìˆ  ë° ì¥ì¹˜
- ë¼ì¦ˆë² ë¦¬íŒŒì´ 5
- ì¹´ë©”ë¼ëª¨ë“ˆ(ENTUS WC33 Full HD 360)
- OpenCV
- Google Cloud Storage
- Django

# ğŸ‘©ğŸ»â€ğŸ’»ì—­í• ë¶„ë‹´
- ê¹€ ì‚°: ì—°ë ¹ëŒ€ êµ¬ë¶„ AI ëª¨ë¸ ì„¤ê³„ ë° ê°œë°œ, ë§ì¶¤ ê´‘ê³  ì¶”ì²œ ë¡œì§ ì„¤ê³„ ë° ê°œë°œ
- ê¹€ë¯¼ìˆ˜: ë‚¨ë…€êµ¬ë¶„ AI ëª¨ë¸ ì„¤ê³„ ë° ê°œë°œ, ì•…ì„¸ì„œë¦¬ ì¸ì‹ AI ëª¨ë¸ ì„¤ê³„ ë° ê°œë°œ
- ì¡°ì˜ì² : ì¹´ë©”ë¼ ëª¨ë“ˆê³¼ ë¼ì¦ˆë² ë¦¬íŒŒì´ì˜ ì—°ë™, AIëª¨ë¸ ì ìš©ê³¼ Django ì„œë²„ì™€ì˜ ì—°ë™ ë° í…ŒìŠ¤íŠ¸
- ì´ì„ í˜¸: í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ êµ¬ì¶• ë° Django ì„œë²„ì™€ ì—°ë™, ì§ê´€ì  ê´‘ê³  ì›¹ í˜ì´ì§€ ê°œë°œ

# ğŸ—ï¸ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜
![ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ drawio](https://github.com/user-attachments/assets/47ff527d-23d6-4266-86c8-66ca3050df6d)
- __ì¸ì‹ë¶€:__ ê´‘ê³ ê°€ ë…¸ì¶œë˜ëŠ” ëª¨ë‹ˆí„°ë¥¼ ë°”ë¼ë³´ê³  ìˆëŠ” ì‚¬ëŒì„ ì¸ì‹í•˜ì—¬ ì‚¬ì§„ì„ ì´¬ì˜ í›„ íŒë‹¨ë¶€ë¡œ ì „ë‹¬
- __íŒë‹¨ë¶€:__ ì´¬ì˜ëœ ì‚¬ì§„ì„ íŒë‹¨ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ì—°ë ¹, ì„±ë³„, ì°©ìš© ì•„ì´í…œì„ êµ¬ë¶„í•˜ì—¬ ë§ì¶¤ ê´‘ê³ ë¥¼ ë§¤í•‘ í›„ ì„œë²„ì— ì „ë‹¬
- __ì„œë²„:__ ê°€ë™ ì‹œ í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ì—ì„œ ê´‘ê³  ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œ, íŒë‹¨ ê²°ê³¼ë¡œ ì „ë‹¬ë°›ì€ ë§ì¶¤ í˜• ê´‘ê³  ì´ë¯¸ì§€ë¥¼ ì‹¤ì§ˆì  ì›¹ í˜ì´ì§€ì— í‘œì‹œ

# ì™„ë£Œ í”¼ë“œë°±
- Success
> AI íŒë‹¨ ëª¨ë¸(ì—°ë ¹, ì„±ë³„, ì•…ì„¸ì„œë¦¬) ê°œë°œ ì™„ë£Œ
> í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ì—ì„œ ê´‘ê³  ì´ë¯¸ì§€ ì—…ë¡œë“œì™€ ì›¹ í˜ì´ì§€ ë¡œë”© í…ŒìŠ¤íŠ¸ ì™„ë£Œ
> ì¹´ë©”ë¼ ëª¨ë“ˆì„ í†µí•œ ì‹¤ì§ˆì  ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

- Exception
> ì•…ì„¸ì„œë¦¬ íŒë‹¨ AI ëª¨ë¸ì˜ ì—°ë™ ì‹¤íŒ¨

<hr>

# [GenderDetection (ì„±ë³„ íŒë‹¨ ëª¨ë¸)](https://github.com/SolarHO/inhatc-24-1/tree/main/Detect)
OpenCVë¥¼ í†µí•´ ì–¼êµ´ ì¸ì‹ <br>
CNNêµ¬ì¡°ë¥¼ í†µí•´ ì„±ë³„ ì¶”ë¡ 
#### ì‚¬ìš© ì½”ë“œ
```
model = Sequential([
    Input(shape=(200, 200, 3)),  # ì…ë ¥ ë°ì´í„° / 200,200 ì‚¬ì´ì¦ˆ 3ê°œì˜ ì±„ë„ (RGB ì»¬ëŸ¬)
    Conv2D(36, kernel_size=3),  # 36ê°œì˜ í•„í„° ì‚¬ì´ì¦ˆ 3*3
    BatchNormalization(),  # ëª¨ë¸ í•™ìŠµ ì•ˆì •í™”
    Activation('relu'),  # relu í™œì„±í™” í•¨ìˆ˜ ì‚¬ìš©
    MaxPooling2D(pool_size=3, strides=2),  # ë‹¤ìš´ìƒ˜í”Œë§ 3*3 ì‚¬ì´ì¦ˆë¡œ 2ì¹¸ì”© ì´ë™
    Conv2D(64, kernel_size=3),  # 64ê°œì˜ í•„í„° ì‚¬ì´ì¦ˆ 3*3
    BatchNormalization(),
    Activation('relu'),
    MaxPooling2D(pool_size=3, strides=2),
    Conv2D(128, kernel_size=3),  # 128ê°œì˜ í•„í„° ì‚¬ì´ì¦ˆ 3*3
    BatchNormalization(),
    Activation('relu'),
    MaxPooling2D(pool_size=3, strides=2),
    Conv2D(256, kernel_size=3),  # 256ê°œì˜ í•„í„° ì‚¬ì´ì¦ˆ 3*3
    BatchNormalization(),
    Activation('relu'),
    MaxPooling2D(pool_size=3, strides=2),
    Conv2D(512, kernel_size=3),  # 512ê°œì˜ í•„í„° ì‚¬ì´ì¦ˆ 3*3
    BatchNormalization(),
    Activation('relu'),
    MaxPooling2D(pool_size=3, strides=2),
    Flatten(),  # ë‹¤ì°¨ì› ë°ì´í„°ë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
    Dropout(0.25),  # ì˜¤ë²„í”¼íŒ…(ê³¼ì í•©) ë°©ì§€ 
    Dense(512, activation='relu'),  # Dense ì•ˆì „ì—°ê²°ë ˆì´ì–´
    Dropout(0.5),
    Dense(2, activation='softmax', name='gender') # ì¶œë ¥ ë°ì´í„° ë‚¨ì„± ì—¬ì„± 2ê°œ
])
```
<hr>

# [AgeDetection (ì—°ë ¹ íŒë‹¨ ëª¨ë¸)](https://github.com/SolarHO/inhatc-24-1/tree/main/ageDetection)

OpenCVì™€ dlibë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ì¸ì‹
- dliv : ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ê¸°ê³„ í•™ìŠµ, ì–¼êµ´ì¸ì‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
- age_deploy.prototxt ê°€ì¤‘ì¹˜ ëª¨ë¸ íŒŒì¼
- age_net.caffemodel í™˜ê²½ íŒŒì¼

### ì—°ë ¹ëª©ë¡
['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']
- ë‚˜ì´ê°€ ë¹„ìŠ·í•œ ì‚¬ëŒë“¤ ì‚¬ì´ì—ì„œëŠ” ì°¨ì´ë¥¼ êµ¬ë³„ë¶ˆê°€, ë¹„ìŠ·í•œ ì–¼êµ´ íŠ¹ì§•ì„ ê³µìœ í•˜ëŠ” ì—°ë ¹ëŒ€ë¥¼ í•˜ë‚˜ì˜ ê·¸ë£¹í™”
- ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ„ë©´ ëª¨ë¸ì´ ì—°ë ¹ ë²”ìœ„ ë‚´ì—ì„œ ì˜¤ì°¨ë¥¼ ë” ì‰½ê²Œ ê´€ë¦¬


### detection.py ì‹¤í–‰ ë°©ë²• 
- python .\detection.py [ì˜ˆì¸¡ ì´ë¯¸ì§€]

![test](https://github.com/user-attachments/assets/8b2414f4-f430-4e1f-b614-d0a6d6097ef3)


â€» dlib ì´ìš© ì‹œ ì•„ë‚˜ì½˜ë‹¤(ê°€ìƒí™˜ê²½ ì‹¤í–‰) í•„ìš”

### ETC
- MiVOLO: Multi-input Transformer for Age and Gender Estimation (ì½”ë„¬ ëŒ€í•™)
- ì–¼êµ´ ì´ë¯¸ì§€ê°€ ë³´ì´ì§€ ì•Šë”ë¼ë„ ëª¸ ì „ì²´ ì´ë¯¸ì§€ë¥¼ í™œìš©í•´ ë‚˜ì´ì™€ ì„±ë³„ì„ ë™ì‹œì— ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ëª¨ë¸
- ì–¼êµ´ê³¼ ëª¸ ì •ë³´ë¥¼ ë™ì‹œì— ì‚¬ìš©í•  ë•Œ ì„±ëŠ¥ì´ ë”ìš± í–¥ìƒ

### ë¹„ì „ íŠ¸ëœìŠ¤í¬ë¨¸ 
- ê¸€ë¡œë²Œ ê´€ê³„ í•™ìŠµ(íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì…€í”„ ì–´í…ì…˜ ì‚¬ìš©)
- ì‘ì€ ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬ í›„ ê´€ê³„ í•™ìŠµ
- ëŒ€ëŸ‰ì˜ ë°ì´í„°ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ ë°œíœ˜

# ì•„ì´í…œ ê²€ì¶œ

## [CapDetection (ëª¨ì ì¸ì‹ ëª¨ë¸)](https://github.com/SolarHO/inhatc-24-1/tree/main/cap_detect_model)
## [AccessoryDetection (ì•…ì„¸ì‚¬ë¦¬ ì¸ì‹ ëª¨ë¸)](https://github.com/SolarHO/inhatc-24-1/tree/main/accessory_detect)

YOLOv5 ëª¨ë¸ ì‚¬ìš©
- YOLO : Object Detection Framework ì¤‘ í•˜ë‚˜
- ì‹¤ì‹œê°„ ê°ì²´ íƒì§€
- ì´ë¯¸ì§€ì™€ ê°ì²´ì˜ ìœ„ì¹˜ì •ë³´ê°€ ë‹´ê²¨ìˆëŠ” ë¼ë²¨ë§ ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµ
- ë°ì´í„° í˜•íƒœ ì˜ˆì‹œ)
  - 5 0.379369 0.419819 0.035085 0.081811
  - 5 0.577118 0.412881 0.032533 0.081332
  - nc: 6  # ì´ í´ë˜ìŠ¤ ê°œìˆ˜
  - names: ['Background', 'Hat', 'Glasses frame', 'Sunglasses', 'Necklace', 'Earrings']
<br>
ì•…ì„¸ì‚¬ë¦¬ ì¸ì‹ ëª¨ë¸
- ëª©ê±¸ì´, ê·€ê±¸ì´, ì„ ê¸€ë¼ìŠ¤, ì•ˆê²½í…Œ ì¸ì‹
<br>

### ëª¨ì ê²€ì¶œ Image ë° ì¸ì‹ë¥ 
![cap1](https://github.com/user-attachments/assets/c177c6ae-e8ed-43d2-8e99-2276f6e00919)

### ì•…ì„¸ì‚¬ë¦¬ ê²€ì¶œ Image ë° ì¸ì‹ë¥ 
![ac](https://github.com/user-attachments/assets/2d2c405c-e053-4e29-87a4-ac74e1e69cf0)

<hr>

# [Recommendation (ê´‘ê³  ì¶”ì²œ)](https://github.com/SolarHO/inhatc-24-1/tree/main/recommendation)
- ì½˜í…ì¸  ê¸°ë°˜ í•„í„°ë§
- CountVectorizerì™€ cosine_similarityë¥¼ ì´ìš©í•œ ê´‘ê³  ì¶”ì²œ
  - CountVectorizer : í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ«ì ë²¡í„°(í–‰ë ¬)ë¡œ ë³€í™˜
  - Cosine Similarity : ë‘ ë²¡í„° ê°„ì˜ ê°ë„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë©°, 0ì—ì„œ 1 ì‚¬ì´ì˜ ê°’ì„ ë°˜í™˜
 
![ì½˜ì²¸ì¸  ê¸°ë°˜](https://github.com/user-attachments/assets/ea0324e0-839a-4d7e-a499-8f5c56501c66)

### ì¥ì 
- ìƒˆë¡œìš´ ì‚¬ìš©ìë¼ë„ ì„ í˜¸ë„ë¥¼ ì¶”ë¡ í•˜ì§€ ì•Šì•„ë„ ì¶”ì²œ ê°€ëŠ¥
- ì œí’ˆ ê°„ì˜ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í™œìš©í•˜ë¯€ë¡œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ì´ ë¹„êµì  ë‚®ìŒ

### ë‹¨ì 
- ì…ë ¥ëœ ì œí’ˆì˜ ì •ë³´ì— êµ­í•œë˜ë¯€ë¡œ ì¶”ì²œ ë²”ìœ„ê°€ ì œí•œì 
 
### ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì˜ ì°¨ì´
|íŠ¹ì§•|ì„ë² ë”©(Embedding)|ì½”ì‚¬ì¸ ìœ ì‚¬ë„(Cosine Similarity)|
|---|---|---|
|ê¸°ëŠ¥|ë°ì´í„°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜ (ë°ì´í„° í‘œí˜„ ë°©ë²•)|ë‘ ë²¡í„° ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •|
|ì…ë ¥|ê³ ì°¨ì› ë°ì´í„°(í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±)|ë‘ ë²¡í„°|
|ì¶œë ¥|ë²¡í„°(ì„ë² ë”© ë²¡í„°)|ìœ ì‚¬ë„ ê°’ (0 ~ 1 ë˜ëŠ” -1 ~ 1)|
|ì ìš© ë‹¨ê³„|ëª¨ë¸ í•™ìŠµ ë˜ëŠ” ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ìƒì„±|ëª¨ë¸ í•™ìŠµ í›„ ë˜ëŠ” ì¶”ì²œ/ê²€ìƒ‰ ë‹¨ê³„ì—ì„œ í™œìš©|
|ì‚¬ìš© ì‚¬ë¡€|ì¶”ì²œ ì‹œìŠ¤í…œ, í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ íŠ¹ì§• í‘œí˜„, ë°ì´í„° ì••ì¶•|ê²€ìƒ‰ ì—”ì§„, ì¶”ì²œ ì‹œìŠ¤í…œ, í´ëŸ¬ìŠ¤í„°ë§, ë¬¸ì„œ/ë¬¸ì¥/ë‹¨ì–´ ìœ ì‚¬ë„ ê³„ì‚°|

- ì½”ì‚¬ì¸ ìœ ì‚¬ë„(Cosine Similarity) ì‚¬ìš© ì´ìœ 
  - CountVectorizerë¥¼ ì‚¬ìš©í•˜ë©´ ê³ ì°¨ì›ì ì¸ ì„ë² ë”© ê³µê°„ì„ êµ¬ì¶•í•  í•„ìš” ì—†ì´ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ì ì¸ íŒ¨í„´ì„ í¬ì°©
  - ì„ë² ë”©ì„ í†µí•œ ê³ ì°¨ì› ë²¡í„° ê³µê°„ ìƒì„±ì€ ì¢…ì¢… ë” ë³µì¡í•˜ê³  ê³„ì‚°ëŸ‰ì´ ë§ì„ ìˆ˜ ìˆìœ¼ë©°, ì´ë¡œ ì¸í•´ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì—ì„œ ì²˜ë¦¬ ì„±ëŠ¥ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•œ ë²¡í„°í™”ëŠ” ê³„ì‚° íš¨ìœ¨ì„±ì„ ë†’ìŒ

### [Recommendation.csv](https://github.com/SolarHO/inhatc-24-1/blob/main/recommendation/data/recommender.csv)

|Index|Age_Group|Sex|Keywords|Product|
|---|---|---|---|---|
|8|8-12|Male|ê²Œì„ ë¦¬ê·¸ì˜¤ë¸Œë ˆì „ë“œ ë©”ì´í”ŒìŠ¤í† ë¦¬ ë¸Œë¡¤ìŠ¤íƒ€ì¦ˆ|ë¬¸í™”ìƒí’ˆê¶Œ
|9|8-12|Male|ê²Œì„ ë¸”ëŸ­ ìŠ¤í‹°ë¸Œ í¬ë¦¬í¼|ë§ˆì¸í¬ë˜í”„íŠ¸
|10|8-12|Female|ìŒì•… ì˜ˆìˆ |í”¼ì•„ë…¸
|11|8-12|Female|ì•„ì´ëŒ ë‹¤ê¾¸ ì•„ì´ë¸Œ|ë‹¤ì´ì–´ë¦¬
|12|8-12|Female|ìºë¦­í„° í† ë¼ ìœ ì•„ê°€ë°© ì–´ë¦°ì´ íŒ¨ì…˜|ê°€ë°©
|13|8-12|Female|ì–´ë¦°ì´ íŒ¨ì…˜ í–‡ë¹›|ëª¨ì
|14|8-12|Female|ìºë¦­í„° ëˆ ì„ ë¬¼|ìºë¦­í„°ì§€ê°‘
<br>

1. ì •í™•ì„±ì„ ë†’ì´ê¸° ìœ„í•œ Kewwords, Product ê²°í•©
  -  df['Combined'] = df['Product'] + ' ' + df['Keywords'].fillna('')

2. CountVectorizerë¡œ í…ìŠ¤íŠ¸ ë²¡í„°í™”
  -  count_vector = CountVectorizer(ngram_range=(1, 3))

3. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
  - combined_c_sim = cosine_similarity(c_vector_combined, c_vector_combined).argsort()[:, ::-1]

### ëª¨ë¸ ì¸ì‹ ìƒíƒœ(ì¹´ë©”ë¼ ì¸ì‹ ìƒíƒœì— ë”°ë¥¸ ì²˜ë¦¬)

- ì—°ë ¹ëŒ€ O ì„±ë³„ O ì°©ìš©ì œí’ˆ O
  + ì—°ë ¹ëŒ€ì™€ ì„±ë³„ì„ ê¸°ì¤€ìœ¼ë¡œ ì œí’ˆ ì¶”ì²œ
  <pre>
  <code>
    product = recommender(Age_Group='8-12', Sex='Female', Item="ê°€ë°©") 
    print(product) # ëª¨ì
  </code>
</pre>

- ì—°ë ¹ëŒ€ O ì„±ë³„ X ì°©ìš©ì œí’ˆ O
  + ì—°ë ¹ëŒ€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì œí’ˆ ì¶”ì²œ
  <pre>
  <code>
    product = recommender(Age_Group='8-12', Item="ê°€ë°©")
    print(product) # ìºë¦­í„°ì§€ê°‘
  </code>
</pre>

- ì—°ë ¹ëŒ€ O ì„±ë³„ X ì°©ìš©ì œí’ˆ X
  + ì—°ë ¹ëŒ€ë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ì œí’ˆ ì¶”ì²œ
  <pre>
  <code>
    product = recommender(Age_Group='8-12')
    print(product) # ë‹Œí…ë„
  </code>
</pre>

- ì—°ë ¹ëŒ€ X ì„±ë³„ X ì°©ìš©ì œí’ˆ X
  + Tableì—ì„œ ëœë¤ìœ¼ë¡œ ì œí’ˆ ì¶”ì²œ
  <pre>
  <code>
    product = recommender()
    print(product) # ê³¨í”„
  </code>
</pre>

## í˜‘ì—… í•„í„°ë§
- ì‚¬ìš©ì ê°„ì˜ í–‰ë™(ì˜ˆ: êµ¬ë§¤, í´ë¦­ ë“±)ì´ë‚˜ ì‚¬ìš©ìì™€ ì•„ì´í…œ ê°„ì˜ ê´€ê³„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ
- ì‚¬ìš©ì ë˜ëŠ” ì œí’ˆì´ ì ì„ ê²½ìš°(íŠ¹íˆ ì‹ ê·œ ì„œë¹„ìŠ¤), ì¶”ì²œ í’ˆì§ˆì´ ë‚®ìŒ
 
# [CameraModule (ì¹´ë©”ë¼ ëª¨ë“ˆ ì—°ë™)](https://github.com/SolarHO/inhatc-24-1/tree/main/camera)

1. ì¹´ë©”ë¼ í”¼ë“œëŠ” OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”ë˜ë©°, í”¼ë“œì— ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì˜¤ë¥˜ë©”ì‹œì§€ì™€ í•¨ê»˜ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë©ë‹ˆë‹¤.
2. ì‚¬ì§„ì„ ì°ëŠ” ë¹ˆë„ëŠ” 5ì´ˆë¡œ ì„¤ì •í–ˆìœ¼ë©°, ì–¼êµ´ì´ ê°ì§€ë˜ë©´ ê° ì–¼êµ´ì˜ ê²½ê³„ ìƒì ì¢Œí‘œë¥¼ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ì˜ì—­ì„ ìë¦…ë‹ˆë‹¤.
3. ê°ì§€ëœ ì–¼êµ´ì„ í†µí•´ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì—°ë ¹ê³¼ ì„±ë³„ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
4. ì˜ˆì¸¡í•œ ì„±ë³„ì˜ˆì¸¡ì˜ ì •í™•ë„ê°€ 80%ì´ìƒì¼ ê²½ìš° ê´‘ê³ ë¥¼ ì¶”ì²œë°›ì•„ Djangoí˜ì´ì§€ì˜ ê´‘ê³ ë¥¼ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤.
5. 2-4ë²ˆ ê³¼ì •ì´ ë°˜ë³µë˜ë©°, 'q'ì…ë ¥ì‹œì— í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.

#### ì¹´ë©”ë¼ëª¨ë“ˆ ìµœì¢…ì½”ë“œ
```
import cv2
import dlib
import numpy as np
from datetime import datetime, timedelta
from google.cloud import storage
from tensorflow.keras.models import load_model
from google.oauth2 import service_account
from tensorflow.keras.preprocessing.image import img_to_array
import recommender_image
import re

#ì¥ê³  ê´€ë ¨ ëª¨ë“ˆ
import os
import shutil
from django.conf import settings

# ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
AGE_MODEL = 'weights/age_deploy.prototxt'
AGE_PROTO = 'weights/age_net.caffemodel'
GENDER_MODEL_PATH = 'gender_classification_cnn_last.h5'
MODEL_MEAN = (78.4263377603, 87.7689143744, 114.895847746)

# DNN ëª¨ë¸ ë¡œë“œ
age_net = cv2.dnn.readNetFromCaffe(AGE_MODEL, AGE_PROTO)
gender_model = load_model(GENDER_MODEL_PATH)

# ë‚˜ì´ ê·¸ë£¹ ë¦¬ìŠ¤íŠ¸
ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-100)']

# ì–¼êµ´ ê²€ì¶œ ëª¨ë¸ ë¡œë“œ
face_detector = dlib.get_frontal_face_detector()

# ì¹´ë©”ë¼ ì„¤ì •
camera = cv2.VideoCapture(0)
capture_interval = 5  # ì´ˆ ë‹¨ìœ„ ìº¡ì²˜ ê°„ê²©
last_capture_time = datetime.now() - timedelta(seconds=capture_interval)

age, gender = None, None

def predict_age_and_gender(face):
    # ë‚˜ì´ ì˜ˆì¸¡
    blob = cv2.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN, swapRB=False)
    age_net.setInput(blob)
    age_preds = age_net.forward()
    age = ageList[age_preds[0].argmax()]
    age = age[1:-1]
    
    # ì„±ë³„ ì˜ˆì¸¡
    face_resized = cv2.resize(face, (200, 200))
    face_resized = img_to_array(face_resized) / 255.0
    face_resized = np.expand_dims(face_resized, axis=0)
    gender_preds = gender_model.predict(face_resized)
    gender = "Female" if np.argmax(gender_preds) == 1 else "Male"
    confidence = np.max(gender_preds) * 100

    return age, gender, confidence
    
#ì¥ê³  í™”ë©´ì— ë„ìš¸ ê´‘ê³  ì´ë¯¸ì§€ ë³€ê²½    
def replace_image(img_path):
    static_image_path = os.path.join('net_Prj', 'static', 'images', 'ad.jpg')  # static ì´ë¯¸ì§€ ê²½ë¡œ(í˜ì´ì§€ì— í‘œì‹œë  ì´ë¯¸ì§€)
    # ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ ìƒˆ ì´ë¯¸ì§€(img_path)ë¡œ êµì²´
    shutil.copy(img_path, '/home/inhatc/django/net_Prj/main/static/images/ad.jpg')

while True:


    ret, frame = camera.read()
    if not ret:
        print("Failed to capture frame")
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_detector(gray)
    
    if faces is None :
        break
    
    if len(faces) > 0 and (datetime.now() - last_capture_time).total_seconds() >= capture_interval:
        last_capture_time = datetime.now()
        
        for face in faces:
            x, y, x2, y2 = face.left(), face.top(), face.right(), face.bottom()
            face_img = frame[y:y2, x:x2]
            
            age, gender, confidence = predict_age_and_gender(face_img)

            # ì–¼êµ´ ì£¼ë³€ì— ì‚¬ê°í˜• ë° ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
            cv2.rectangle(frame, (x, y), (x2, y2), (0, 200, 200), 2)
            cv2.putText(frame, f"{age}, {gender} ({confidence:.2f}%)", (x, y - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        # ì´ë¯¸ì§€ ì €ì¥
        #timestamp = last_capture_time.strftime('%Y%m%d_%H%M%S')
        #filename = f"person_detected_{timestamp}.jpg"
        #cv2.imwrite(filename, frame)
        #print(f"Image saved: {filename}")
        print(age)
        print(gender)
        print(confidence)

        #ì •í™•ë„ê°€ 80ì´ìƒì¼ë–¼ë§Œ ê´‘ê³  ë³€ê²½
        if(confidence >= 80) :
            prd, img = recommender_image.recommender(Age_Group=age, Sex=gender, Item=None)
            print(prd)
            print(img)
            
            replace_image(img)#ì¥ê³  í™”ë©´ì— ë„ìš¸ ê´‘ê³  ì´ë¯¸ì§€ ë³€ê²½
            image = cv2.imread(img)
            cv2.imshow('test',image)
        
        # #í´ë¼ìš°ë“œì— íŒŒì¼ ì—…ë¡œë“œ
        # image_path = f"/home/inhatc/project/{filename}"
        # bucket_name = "inhatc_test"
        # destination_blob_name = f"test/test_{timestamp}.jpg"
        # credentials_path = "/home/inhatc/project/fluted-polymer-440606-a2-450d3d134caa.json"
        
        # upload_image_to_gcs(image_path, bucket_name, destination_blob_name, credentials_path)
        
    cv2.imshow("Camera", frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

camera.release()
cv2.destroyAllWindows()
```
